{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import LlamaTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./llama-coder\"\n",
    "final_checkpoint_dir = os.path.join(output_dir, \"final_checkpoint\")\n",
    "model_id=\"./models/7B-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.89s/it]\n",
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ./models/7B-hf and are newly initialized: ['model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tuned_model = AutoPeftModelForCausalLM.from_pretrained(final_checkpoint_dir, device_map='auto', torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Implement the following program given the instructions:\n",
      "Write a simple program to calculate the cosine similarity between two vectors in Typescript.\n",
      "\n",
      "Code:\n",
      "Here is some sample typescript code which implements cosine similarity calculation based on given input vectors:\n",
      "\n",
      " ```typescript\n",
      "function calculateCosineSimilarity(vector1: number[], vector2: number[]): number {\n",
      "  const len1 = vector1.length;\n",
      "  const len2 = vector2.length;\n",
      "\n",
      "  // Compute dot product of vectors\n",
      "  const dotProduct = vector1.reduce((acc, curr) => acc + curr * vector2[i], 0);\n",
      "\n",
      "  // Compute cosine similarity\n",
      "  const cosineSimilarity = Math.acos((dotProduct / (len1 * len2)));\n",
      "\n",
      "  return cosineSimilarity;\n",
      "}\n",
      "\n",
      "// Example usage\n",
      "const vector1 = [1, 2, 3];\n",
      "const vector2 = [4, 5, 6];\n",
      "\n",
      "console.log(calculateCosineSimilarity(vector1, vector2)); // Output: 0.9090909090909091\n",
      "```\n",
      "In this function we first compute the dot product of two vectors by iterating over each element of both vectors and adding them together\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "Implement the following program given the instructions:\n",
    "Write a simple program to calculate the cosine similarity between two vectors in Typescript.\n",
    "\n",
    "Code:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(tuned_model.generate(**model_input, max_new_tokens=256)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
