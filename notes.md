


Server options: https://github.com/abetlen/llama-cpp-python/blob/main/llama_cpp/server/app.py

https://github.com/abetlen/llama-cpp-python/blob/main/examples/high_level_api/fastapi_server.py


Performance: https://huggingface.co/docs/transformers/v4.31.0/en/perf_train_gpu_one

https://huggingface.co/docs/transformers/v4.31.0/en/perf_train_gpu_one#using-accelerate